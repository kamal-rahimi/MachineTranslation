{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r \"requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" tools.py\n",
    "This file provides some helper functions required to read and prepare data\n",
    "for the model\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "SPLIT_PATTERN_WITH_DILIMITER = r'([`\\-=~!@#$%^&*()_+\\[\\]{};\\'\\\\:\"|<,./<>?\\n\\s])\\s*'\n",
    "SPLIT_PATTERN_NO_DILIMITER   = r'[`\\-=~!@#$%^&*()_+\\[\\]{};\\'\\\\:\"|<,./<>?\\n\\s]\\s*'\n",
    "\n",
    "\n",
    "def read_data(data_path):\n",
    "    \"\"\" Reads data from an excel file\n",
    "    Args:\n",
    "        data_path: Input data path\n",
    "    Returns:\n",
    "        qids_raw: Pyhon list of raw qid texts\n",
    "        conditions_raw: Pyhon list of raw condition texts\n",
    "        outputs_raw: Pyhon list of raw output texts\n",
    "    \"\"\"\n",
    "    data_set = pd.read_excel(data_path)\n",
    "    qids_raw       = data_set[\"QID\"].values\n",
    "    conditions_raw = data_set[\"CONDITION\"].values\n",
    "    outputs_raw    = data_set[\"OUTPUT\"].values\n",
    "    return qids_raw, conditions_raw, outputs_raw\n",
    "\n",
    "def write_data(qids, conditions, outputs, data_path):\n",
    "    \"\"\" Writes data to an excel file\n",
    "    Args:\n",
    "        qids: Pyhon list of qid texts\n",
    "        conditions: Pyhon list of condition texts\n",
    "        outputs: Pyhon list of output texts\n",
    "    Return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    data_set = pd.DataFrame(list(zip(qids, conditions, outputs)),\n",
    "                            columns=[\"QID\", \"CONDITION\", \"OUTPUT\"])\n",
    "    data_set.to_excel(data_path)\n",
    "\n",
    "\n",
    "def prepare_data(qids_raw, conditions_raw, outputs_raw):\n",
    "    \"\"\" Prepares data for the model\n",
    "    Args:\n",
    "        qids_raw: Pyhon list of raw qid texts\n",
    "        conditions_raw: Pyhon list of raw condition texts\n",
    "        outputs_raw: Pyhon list of raw output texts\n",
    "    Returns:\n",
    "        qids: Pyhon list of preprocessed qid sequnces\n",
    "        conditions: Pyhon list of preprocessed condition sequnces\n",
    "        outputs: Pyhon list of preprocessed output sequnces\n",
    "        dictionaries_standardization: Pyhton list of dictionaries used for standardizing samples\n",
    "    \"\"\"\n",
    "\n",
    "    qids = []\n",
    "    conditions = []\n",
    "    outputs = []\n",
    "    dictionaries_standardization = []\n",
    "    for qid_raw, condition_raw, output_raw in zip(qids_raw, conditions_raw, outputs_raw):\n",
    "        qid, condition, output, dictionary = preprocess_sample(qid_raw, condition_raw, output_raw)\n",
    "        qids.append(qid)\n",
    "        conditions.append(condition)\n",
    "        outputs.append(output)\n",
    "        dictionaries_standardization.append(dictionary)\n",
    "\n",
    "    return qids, conditions, outputs, dictionaries_standardization\n",
    "\n",
    "def preprocess_sample(qid_raw, condition_raw, output_raw):\n",
    "    \"\"\" Preproces a sample to create standarized sequnces\n",
    "        a. Change qid_raw, condition_raw and output_raw text to lowercas\n",
    "        b. split qid_raw, condition_raw and output_raw text into tokens (words)\n",
    "        c. Replace qid_raw tokens with standrized tokens (i.e., <QID0>, <QID1>, ...)\n",
    "        d. Replace digit tokens with standarized tokens (i.e., <DGT0>, <DGT1>, ...)\n",
    "        e. Create standardization dictionary for each sample\n",
    "        f. Add special tokens <BOS> and <EOS> to the begining and end of each sequence\n",
    "    \"\"\"\n",
    "    qid, condition, output = split_to_words(qid_raw, condition_raw, output_raw)\n",
    "    \n",
    "    qid, condition, output, dictionary_standardization = standardize_words(qid, condition, output)\n",
    "\n",
    "    return qid, condition, output, dictionary_standardization\n",
    "\n",
    "def split_to_words(qid_raw, condition_raw, output_raw):\n",
    "    \"\"\" Splits input raw texts into words (tokens)\n",
    "    Args:\n",
    "        qid_raw: raw qid text\n",
    "        condition_raw: Pyhon list of raw condition texts\n",
    "        output_raw: raw output texts\n",
    "    Return:\n",
    "        qid: Python array of qid words (tokens)\n",
    "        condition: Python array of condition words (tokens)\n",
    "        output: Python array of output words (tokens)\n",
    "    \"\"\"\n",
    "    qid       = re.split(SPLIT_PATTERN_NO_DILIMITER, str(qid_raw))\n",
    "    condition = re.split(SPLIT_PATTERN_NO_DILIMITER, str(condition_raw))\n",
    "    condition = [cond for cond in condition if cond != \" \" and cond != \"\"]\n",
    "    output    = re.split(SPLIT_PATTERN_WITH_DILIMITER, str(output_raw))\n",
    "\n",
    "    qid       = [x.lower() for x in qid]\n",
    "    condition = [x.lower() for x in condition]\n",
    "    output    = [x.lower() for x in output]\n",
    "    \n",
    "    return qid, condition, output\n",
    "\n",
    "def standardize_words(qid, condition, output):\n",
    "    \"\"\" Standarizes a sample by replacing qids and digits with stanadard words\n",
    "    Args:\n",
    "        qid: Python array of qid words (tokens)\n",
    "        condition: Python array of condition words (tokens)\n",
    "        output: Python array of output words (tokens)\n",
    "    Retursn:\n",
    "        qid: Python array of standarized qid words (tokens)\n",
    "        condition: Python array of standarized condition words (tokens)\n",
    "        output: Python array of standarized output words (tokens)\n",
    "        dictionary_standardization: Pyhton dictionary used for standardizing sample\n",
    "    \"\"\"\n",
    "    dictionary_standardization = {}\n",
    "    for index, id in enumerate(qid):\n",
    "        standard_qid = '<QID{}>'.format(index)\n",
    "        dictionary_standardization[standard_qid] = qid[index]\n",
    "        qid[index] = standard_qid\n",
    "    \n",
    "        for word_index in range(len(condition)):\n",
    "            if condition[word_index] == id:\n",
    "                condition[word_index] = standard_qid\n",
    "\n",
    "        for word_index in range(len(output)):\n",
    "            if output[word_index] == id:\n",
    "                output[word_index] = standard_qid\n",
    "\n",
    "    digit_num = 0\n",
    "    for word in condition:\n",
    "        if word.isdigit():\n",
    "            standard_digit = '<DGT{}>'.format(digit_num)\n",
    "            digit_num += 1\n",
    "            dictionary_standardization[standard_digit] = word\n",
    "\n",
    "            for word_index in range(len(condition)):\n",
    "                if condition[word_index] == word:\n",
    "                    condition[word_index] = standard_digit\n",
    "\n",
    "            for word_index in range(len(output)):\n",
    "                if output[word_index] == word:\n",
    "                    output[word_index] = standard_digit\n",
    "\n",
    "    for word in output:\n",
    "        if word.isdigit():\n",
    "            standard_digit = '<DGT{}>'.format(digit_num)\n",
    "            digit_num += 1\n",
    "            dictionary_standardization[standard_digit] = word\n",
    "            for word_index in range(len(output)):\n",
    "                if output[word_index] == word:\n",
    "                    output[word_index] = standard_digit\n",
    "    \n",
    "    condition   = ['<BOS>']  + condition + ['<EOS>']\n",
    "    output      = ['<BOS>']  + output  + ['<EOS>']\n",
    "\n",
    "    return qid, condition, output, dictionary_standardization\n",
    "\n",
    "\n",
    "def create_vocabulary(word_list, max_vocab_size):\n",
    "    \"\"\" Create Vocabulary dictionary\n",
    "    Args:\n",
    "        text(str): inout word list\n",
    "        max_vocab_size: maximum number of words in the vocabulary\n",
    "    Returns:\n",
    "        word2id(dict): word to id mapping\n",
    "        id2word(dict): id to word mapping\n",
    "    \"\"\"\n",
    "    words = [word for sample in word_list for word in sample]\n",
    "    freq = Counter(words)\n",
    "    word2id = {'<PAD>' : 0}\n",
    "    id2word = {0 : '<PAD>'}\n",
    "\n",
    "    for word, _ in freq.most_common():\n",
    "        id = len(word2id)\n",
    "        if word not in word2id:\n",
    "            word2id[word] = id\n",
    "            id2word[id] = word\n",
    "        if id == max_vocab_size - 1 :\n",
    "            break\n",
    "\n",
    "    return word2id, id2word\n",
    "\n",
    "\n",
    "def replace_using_dict(list, dictionary, drop_unknown=False):\n",
    "    \"\"\" Replaces tokens of the input list using a dictionary\n",
    "    Args:\n",
    "        list: a python list of word sequences\n",
    "        dictionary: a dictionary to convert tokens\n",
    "        drop_unknown: a flag to specify whether keep or drop tokens not in dictionary\n",
    "    Returns:\n",
    "        replaced_list: replaced Pyhthon list of word sequences \n",
    "\n",
    "    \"\"\"\n",
    "    replaced_list = []\n",
    "    for line in list:\n",
    "        if drop_unknown:\n",
    "            translated_line = [dictionary[word] for word in line if word in dictionary]\n",
    "        else:\n",
    "            translated_line = [dictionary[word] if word in dictionary else word for word in line]\n",
    "        replaced_list.append(translated_line)\n",
    "    \n",
    "    return replaced_list\n",
    "\n",
    "def pad_with_zero(list, max_length, pad_type):\n",
    "    \"\"\" Pad sequnces in the input list with zero\n",
    "    Args:\n",
    "        list: a Python list of word sequnces\n",
    "        max_length: maximum length of each sequence\n",
    "        pad_type: whether pad begining or end of the sequnces\n",
    "    Return:\n",
    "        padded_list: padded list of word sequnces\n",
    "    \"\"\"\n",
    "    padded_list = pad_sequences(list, maxlen=max_length, padding=pad_type, truncating='post')\n",
    "    return padded_list\n",
    "\n",
    "\n",
    "def log_to_shell(index, qid_raw, condition_raw, output_raw, decoded_seqeunce):\n",
    "    \"\"\" Prints information to shell\n",
    "    Args:\n",
    "        qid_raw: raw qid text\n",
    "        condition_raw: Pyhon list of raw condition texts\n",
    "        output_raw: raw output texts\n",
    "        decoded_seqeunce: decoded output sequnce\n",
    "    Return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    print(\"Sample index\",       index)\n",
    "    print(\"QID: \",              qid_raw)\n",
    "    print(\"CONDITION: \",        condition_raw)\n",
    "    print(\"OUTPUT: \",           output_raw,'\\n')\n",
    "    print(\"Predicted OUTPUT: \", decoded_seqeunce, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded train data set from [./data/MT_training_corpus.xlsx]\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, None, 150)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 40), (None,  30560       encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 40), ( 14560       decoder_input[0][0]              \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 50)     2050        decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 47,170\n",
      "Trainable params: 47,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      " - 6s - loss: 1.7975 - acc: 0.6267 - val_loss: 1.0971 - val_acc: 0.7808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamal/.local/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer decoder_lstm was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'encoder_lstm_3/while/Exit_2:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'encoder_lstm_3/while/Exit_3:0' shape=(?, 40) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      " - 3s - loss: 0.8270 - acc: 0.8185 - val_loss: 0.6358 - val_acc: 0.8542\n",
      "Epoch 3/30\n",
      " - 2s - loss: 0.5492 - acc: 0.8712 - val_loss: 0.6033 - val_acc: 0.8408\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.3631 - acc: 0.9063 - val_loss: 0.5691 - val_acc: 0.8606\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.3066 - acc: 0.9190 - val_loss: 0.3931 - val_acc: 0.8994\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.1665 - acc: 0.9604 - val_loss: 0.4885 - val_acc: 0.8950\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.2141 - acc: 0.9459 - val_loss: 0.3438 - val_acc: 0.9194\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.1715 - acc: 0.9597 - val_loss: 0.2417 - val_acc: 0.9350\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.1536 - acc: 0.9626 - val_loss: 0.2752 - val_acc: 0.9294\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.1252 - acc: 0.9715 - val_loss: 0.2363 - val_acc: 0.9447\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.1263 - acc: 0.9690 - val_loss: 0.2116 - val_acc: 0.9456\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.1068 - acc: 0.9740 - val_loss: 0.0991 - val_acc: 0.9714\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.0985 - acc: 0.9781 - val_loss: 0.1361 - val_acc: 0.9631\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.0751 - acc: 0.9814 - val_loss: 0.1617 - val_acc: 0.9544\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.0893 - acc: 0.9791 - val_loss: 0.1960 - val_acc: 0.9536\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.0604 - acc: 0.9885 - val_loss: 0.1813 - val_acc: 0.9533\n",
      "Epoch 17/30\n",
      " - 3s - loss: 0.0550 - acc: 0.9882 - val_loss: 0.1371 - val_acc: 0.9542\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.0596 - acc: 0.9864 - val_loss: 0.2020 - val_acc: 0.9569\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.0519 - acc: 0.9882 - val_loss: 0.2470 - val_acc: 0.9556\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.0405 - acc: 0.9914 - val_loss: 0.1546 - val_acc: 0.9686\n",
      "Epoch 21/30\n",
      " - 3s - loss: 0.0559 - acc: 0.9882 - val_loss: 0.1430 - val_acc: 0.9658\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.0632 - acc: 0.9863 - val_loss: 0.1898 - val_acc: 0.9414\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.0296 - acc: 0.9940 - val_loss: 0.1921 - val_acc: 0.9458\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.0308 - acc: 0.9941 - val_loss: 0.2908 - val_acc: 0.9386\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.0358 - acc: 0.9927 - val_loss: 0.3058 - val_acc: 0.9242\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.0427 - acc: 0.9912 - val_loss: 0.1626 - val_acc: 0.9619\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.0372 - acc: 0.9920 - val_loss: 0.2202 - val_acc: 0.9467\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.0335 - acc: 0.9923 - val_loss: 0.1942 - val_acc: 0.9636\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.0449 - acc: 0.9893 - val_loss: 0.1903 - val_acc: 0.9528\n",
      "Epoch 30/30\n",
      " - 3s - loss: 0.0391 - acc: 0.9907 - val_loss: 0.1305 - val_acc: 0.9606\n",
      "\n",
      "Trained seq2seq model saved in [./model/mt_seq2seq_model.h5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\" train.py\n",
    "This file reads and preproces the train dataset and builds a seq2seq model\n",
    "using Recurrent Neurak Networks to predict a target sequnce from an input sequnce.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "### Import required packages\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from keras.models import Model, Input, load_model\n",
    "from keras.layers import Embedding, LSTM, Dense, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "## Import helper functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tools import read_data, prepare_data, create_vocabulary, replace_using_dict, pad_with_zero\n",
    "\n",
    "## Define default training data path\n",
    "MT_TRAINING_CORPUS_PATH  = \"./data/MT_training_corpus.xlsx\"\n",
    "\n",
    "## Specify path to save model and metadata\n",
    "MT_SEQ2SEQ_MODEL_PATH    = \"./model/mt_seq2seq_model.h5\"\n",
    "MT_MODEL_CHECKPOINT_PATH = \"./model/model.chpt\"\n",
    "MT_META_DATA_FILE_PATH   = \"./model/metadata.pickle\"\n",
    "\n",
    "## Define model parameter\n",
    "# Encoder and Decoder maximum vocabulary size\n",
    "encoder_vocab_size = 150\n",
    "decoder_vocab_size = 50\n",
    "\n",
    "# Encoder and Decoder sequnces length\n",
    "encoder_seq_length = 20\n",
    "decoder_seq_length = 15\n",
    "\n",
    "# Number of training epcohs\n",
    "num_epochs = 30\n",
    "\n",
    "# Training Batch size\n",
    "batch_size = 20\n",
    "\n",
    "# Number of LSTM latend dimention in both Encoder and Decoder\n",
    "num_latent_dim = 40\n",
    "\n",
    "# Fraction of data used for validation during training the model\n",
    "validation_size = 0.1\n",
    "\n",
    "def data_generator(X, y, batch_size):\n",
    "    \"\"\" Creates a data genrator to feed encoder and decoder input sequnces and decoder\n",
    "    target sequnce\n",
    "    Args:\n",
    "        X: input sequnces\n",
    "        y: target sequnces\n",
    "    Returns:\n",
    "         yields a batch of encoder and decoder input sequnces and decoder target sequnce\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for j in range(random.randint(1,len(X)-batch_size)):\n",
    "            encoder_input_sequnce  = np.zeros((batch_size, encoder_seq_length, encoder_vocab_size), dtype='float32')\n",
    "            decoder_input_sequnce  = np.zeros((batch_size, decoder_seq_length, decoder_vocab_size), dtype='float32')\n",
    "            decoder_target_sequnce = np.zeros((batch_size, decoder_seq_length, decoder_vocab_size), dtype='float32')\n",
    "\n",
    "            for i, (input_seq, target_seq) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_seq):\n",
    "                    encoder_input_sequnce[i, t, word] = 1  # encoder input seq\n",
    "                for t, word in enumerate(target_seq):\n",
    "                    if t < decoder_seq_length:\n",
    "                        decoder_input_sequnce[i, t, word] = 1 # decoder input seq\n",
    "                    if t>0:\n",
    "                        decoder_target_sequnce[i, t-1, word] = 1 # decoder target seq\n",
    "\n",
    "            yield([encoder_input_sequnce, decoder_input_sequnce], decoder_target_sequnce)            \n",
    " \n",
    "\n",
    "def create_seq2seq_model(encoder_vocab_size, decoder_vocab_size, latent_dim):\n",
    "    \"\"\" Creates a seq2seq model using Recurrent Neural Networks(RNN).\n",
    "    The encoder consists of a left-to-right LSTM layer and outputs states to decoder.\n",
    "    The decoder is also consists of a left-to-right LSTM layer and outputs a sequence that\n",
    "    are fed to time distributed fully connected layers with softmax activation to predict \n",
    "    target sequence. \n",
    "    Args:\n",
    "        encoder_vocab_size: number of encoder tokens (i.e., encoder vocab size)\n",
    "        decoder_vocab_size: size of  decoder tokens (i.e., decoder vocab size)\n",
    "        latent_dim: number of LSTM hidden dimenetions\n",
    "    Returns:\n",
    "        model: seq2seq model\n",
    "    \"\"\"\n",
    "\n",
    "    ### Encoder\n",
    "    ## Input layer\n",
    "    encoder_inputs = Input(shape=(None, encoder_vocab_size), name='encoder_input')\n",
    "    ## LSTM layer\n",
    "    encoder = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    # We keep encoder states and discard encoder ouput.\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    ### Decoder\n",
    "    ## Input layer\n",
    "    decoder_inputs = Input(shape=(None, decoder_vocab_size), name='decoder_input')\n",
    "    ## Left to right LSTM layer\n",
    "    # We set up our decoder to return full output sequences,\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                        initial_state=encoder_states)\n",
    "    ## Fully connected layer\n",
    "    decoder_dense = Dense(decoder_vocab_size, activation='softmax', name='decoder_dense')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    ### Model to jointly train Encoder and Decoder \n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_seq2seq_inference_model(model, latent_dim):\n",
    "    \"\"\" Creates a seq2seq inference model by extracting Encoder and Decoder models\n",
    "     from the input seq2seq model.\n",
    "    Args:\n",
    "        model: a seq2seq model\n",
    "        laten_dim: number of latent dimention of the seq2seq model\n",
    "    Returns:\n",
    "        encoder_model: encoder model of input seq2seq model\n",
    "        decoder_model: decoder model of input seq2seq model\n",
    "    \"\"\"\n",
    "    ### Inference Model\n",
    "    # 1. Encode the input sequence using Encoder and return state for decoder input\n",
    "    # 2. Run one step of decoder with this intial state and \"start of sequnce\" token\n",
    "    #  as input. The output will be used as the next decoder input sequnce token\n",
    "    # 3. This procedure is repteated to predict all output sequnce \n",
    "    \n",
    "    ### Encoder Model\n",
    "    encoder_inputs = model.input[0] \n",
    "    encoder_outputs, state_h_enc, state_c_enc = model.get_layer('encoder_lstm').output   # lstm_1\n",
    "    encoder_states = [state_h_enc, state_c_enc]\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    ### Decoder Model\n",
    "    ## Decoder State Input\n",
    "    decoder_inputs = model.input[1]\n",
    "    decoder_state_input_h = Input(shape=(latent_dim,), name='input_3')\n",
    "    decoder_state_input_c = Input(shape=(latent_dim,), name='input_4')\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    ## Decoder LSTM layer\n",
    "    decoder_lstm = model.get_layer('decoder_lstm')\n",
    "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h_dec, state_c_dec]\n",
    "    ## Decoder Fully connected layer\n",
    "    decoder_dense = model.get_layer('decoder_dense')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
    "                            [decoder_outputs] + decoder_states)\n",
    "\n",
    "    return encoder_model, decoder_model\n",
    "\n",
    "def train_seq2seq_model(model, X_train, X_valid, y_train, y_valid, epochs):\n",
    "    \"\"\" Compiles and trains the seq2seq model. The train data is fed to model\n",
    "    using a generator function\n",
    "    Args:\n",
    "        model: seq2seq model\n",
    "        X_train: train data input sequnce (conditions)\n",
    "        X_valid: train data input sequnce (conditions)\n",
    "        y_train: validation target sequnce sequnce (ouputs)\n",
    "        y_valid: validation target sequnce (ouputs)\n",
    "        epochs: number of epochs to train model\n",
    "    Returns:\n",
    "        model: trained seq2seq model\n",
    "    \"\"\"\n",
    "\n",
    "    # Model is trainined to minimize cross enthrop between true target sequnce\n",
    "    # and predicted target sequnce\n",
    "    # Optimizer is set to Nadam and accuracy is used as metric\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='Nadam',\n",
    "                    metrics=['acc'])\n",
    "    \n",
    "    # Creats data genrators to feed train and validation data\n",
    "    train_data_generator = data_generator(X_train, y_train, batch_size)\n",
    "    valid_data_generator = data_generator(X_valid, y_valid, batch_size)\n",
    "    \n",
    "    # Define callback fo model checkpoint\n",
    "    callbacks = [ModelCheckpoint(MT_MODEL_CHECKPOINT_PATH, save_best_only=True, save_weights_only=False)]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit_generator(train_data_generator,\n",
    "                        validation_data=valid_data_generator,\n",
    "                        epochs=epochs,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=2,\n",
    "                        steps_per_epoch=len(X_train)/batch_size,\n",
    "                        validation_steps=len(X_valid)/batch_size)\n",
    "\n",
    "    return model\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \"\"\" The main steps to train a seq2seq model:\n",
    "    1. Read dataset\n",
    "    2. Preproces each sequnce (create standarized sequnces)\n",
    "        a. Change QID, CONDITION and OUTPUT text to lowercase\n",
    "        b. split QID, CONDITION and OUTPUT text into tokens (words)\n",
    "        c. Replace QID tokens in each sample with standrized tokens (i.e., <QID0>, <QID1>, ...)\n",
    "        d. Replace digit tokens in each sample with standarized tokens (i.e., <DGT0>, <DGT1>, ...)\n",
    "        e. Create standardization dictionary for each sample\n",
    "        f. Add special tokens <BOS> and <EOS> to the begining and end of each sequence\n",
    "    3. Create dictinries to convert input and target sequnces to an integer id\n",
    "    4. Replace input and outpu sequnce tokens with an integre id\n",
    "    5. Pad sequnces with zero to create fixed size input and target sequnces\n",
    "        a. Input sequnce is pre-padded with zero\n",
    "        b. Target sequnce is post-padded \n",
    "    4. Create a seq2seq model\n",
    "    4. Train the model\n",
    "    5. Save the model and model metadata (inclding dictionaries to conver words to id)\n",
    "    \"\"\"\n",
    "\n",
    "    # Train data path\n",
    "    train_data_path = MT_TRAINING_CORPUS_PATH\n",
    "\n",
    "    if not os.path.exists(train_data_path):\n",
    "        print(\"\\n Specified train data path [%s] does not exist\\n\" % train_data_path)\n",
    "        return\n",
    "\n",
    "    # Read dataset from Excel file\n",
    "    qids_raw, conditions_raw, output_raw = read_data(train_data_path)\n",
    "    print(\"\\nLoaded train data set from [{}]\\n\".format(train_data_path))\n",
    "\n",
    "    # Preprocess the raw input text data\n",
    "    _, conditions, outputs, dictionaries_lemanization = prepare_data(qids_raw, conditions_raw, output_raw)\n",
    "    \n",
    "    # Create dictionaries to convert between word and an integer id\n",
    "    # for conditions (Human Longuage) and ouputs (Machine longuage)\n",
    "    condition_word2id, condition_id2word = create_vocabulary(conditions, encoder_vocab_size)\n",
    "    output_word2id, output_id2word = create_vocabulary(outputs, decoder_vocab_size)\n",
    "    \n",
    "    # Replace words of condition and ouput with corresponding id in dictonaries\n",
    "    conditions = replace_using_dict(conditions, condition_word2id, drop_unknown=True)\n",
    "    outputs    = replace_using_dict(outputs, output_word2id, drop_unknown=True)\n",
    "\n",
    "    # Fix all sequnces length to a fixed size with padding\n",
    "    conditions = pad_with_zero(conditions, encoder_seq_length,'pre')\n",
    "    outputs    = pad_with_zero(outputs, decoder_seq_length+1,'post')\n",
    "\n",
    "    # Split train data into train and validation sets\n",
    "    conditions_train, conditions_valid, outputs_train, outputs_valid = train_test_split(conditions, outputs, test_size=validation_size, random_state=42)\n",
    "\n",
    "    # Created a seq2seq Recurrent Neural Network model\n",
    "    model = create_seq2seq_model(encoder_vocab_size, decoder_vocab_size, num_latent_dim)\n",
    "    model.summary()\n",
    "    \n",
    "    # Train the seq2seq model\n",
    "    model = train_seq2seq_model(model, conditions_train, conditions_valid, outputs_train, outputs_valid, num_epochs)\n",
    "\n",
    "    # Save model and metadata\n",
    "    model.save(MT_SEQ2SEQ_MODEL_PATH)\n",
    "    with open(MT_META_DATA_FILE_PATH,'wb') as f:\n",
    "        pickle.dump([condition_word2id,condition_id2word, output_word2id, output_id2word], f)\n",
    "    \n",
    "    print(\"\\nTrained seq2seq model saved in [{}]\\n\".format(MT_SEQ2SEQ_MODEL_PATH))\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded a trained seq2seq model from [./model/mt_seq2seq_model.h5]\n",
      "\n",
      "\n",
      "Loaded test dataset from [./data/MT_test_submission.xlsx]\n",
      "\n",
      "Sample index 0\n",
      "QID:  1010\n",
      "CONDITION:  Terminate if respondent selected ‘A4’ for all 3 product types\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  1010.any() \n",
      "\n",
      "\n",
      "Sample index 10\n",
      "QID:  Q16A,QD\n",
      "CONDITION:  ASK ONLY IF QD = 1-4 (ORDERED ANY TEST SALAD)\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  qd.between(1:4) \n",
      "\n",
      "\n",
      "Sample index 20\n",
      "QID:  QR8,Q30,QR7\n",
      "CONDITION:  ASK IF Q30=1 AND QR7=1-4\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q30.any(1)&q30.any(4) \n",
      "\n",
      "\n",
      "Sample index 30\n",
      "QID:  8014\n",
      "CONDITION:  END Younger than 18 years\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:   \n",
      "\n",
      "\n",
      "Sample index 40\n",
      "QID:  Q26B,QE2\n",
      "CONDITION:  ASK ONLY IF QE2=1\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  qe2.any(1) \n",
      "\n",
      "\n",
      "Sample index 50\n",
      "QID:  Q3,Q2\n",
      "CONDITION:  ASK IF Q2=1\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q2.any(1) \n",
      "\n",
      "\n",
      "Sample index 60\n",
      "QID:  Q17b,QD\n",
      "CONDITION:  ASK ONLY IF QD = 1 (ORDERED BIG TEX TACO SALAD)\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  qd.any(1) \n",
      "\n",
      "\n",
      "Sample index 70\n",
      "QID:  8000\n",
      "CONDITION:  Screen out if NOT 2\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  8000.notany(2) \n",
      "\n",
      "\n",
      "Sample index 80\n",
      "QID:  Q25B,QE2\n",
      "CONDITION:  ASK ONLY IF QE2=1\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  qe2.any(1) \n",
      "\n",
      "\n",
      "Sample index 90\n",
      "QID:  22015,22011\n",
      "CONDITION:  ASK IF CODED 2 AT 22011 \n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  22011.any(2) \n",
      "\n",
      "\n",
      "Sample index 100\n",
      "QID:  Q3A,QA\n",
      "CONDITION:  ASK IF QA = 1 (WOMEN)\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  qa.any(1) \n",
      "\n",
      "\n",
      "Sample index 110\n",
      "QID:  6223,Q6215\n",
      "CONDITION:  Instructions: only show if HCP prescribed or recommended one brand = Q6215 A1 OR A2\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q6215.any(,) \n",
      "\n",
      "\n",
      "Sample index 120\n",
      "QID:  Q4654,Q4200\n",
      "CONDITION:  ROUTING IF: respondent answers 2 @q4200\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q4200.any(2) \n",
      "\n",
      "\n",
      "Sample index 130\n",
      "QID:  1011,1010\n",
      "CONDITION:  Ask this question only to those select ‘A2’ or ‘A4’ for ALL product types at 1010\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  1010.any(,) \n",
      "\n",
      "\n",
      "Sample index 140\n",
      "QID:  20043,20033\n",
      "CONDITION:  ROUTING: A1/A2/A3/A4/A5 IN 20033\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  20033.any(,,,,) \n",
      "\n",
      "\n",
      "Sample index 150\n",
      "QID:  Q25C,Q25B\n",
      "CONDITION:  ASK ONLY IF Q25B=1 \n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q25b.any(1) \n",
      "\n",
      "\n",
      "Sample index 160\n",
      "QID:  Q306,Q305\n",
      "CONDITION:  Q306 IF NOT 6 IN Q305\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q305.notany(6) \n",
      "\n",
      "\n",
      "Sample index 170\n",
      "QID:  D14,D13,D15\n",
      "CONDITION:  [PN : IF D13=99, GO TO D15]\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  d13.any(99) \n",
      "\n",
      "\n",
      "Sample index 180\n",
      "QID:  41962,4006\n",
      "CONDITION:  Ask to those coded 2 in 4006\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  4006.any(2) \n",
      "\n",
      "\n",
      "Sample index 190\n",
      "QID:  QD\n",
      "CONDITION:  QUESTION : DROP DOWN LIST IF QD = 52\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  qd.any(52) \n",
      "\n",
      "\n",
      "Sample index 200\n",
      "QID:  Q226,Q225\n",
      "CONDITION:  ASK Q226 IF NOT 5 IN Q225\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q225.notany(5) \n",
      "\n",
      "\n",
      "Sample index 210\n",
      "QID:  Q1004\n",
      "CONDITION:  Screenout if respondent is an experienced mum: Q1004 A2\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q1004.any() \n",
      "\n",
      "\n",
      "Sample index 220\n",
      "QID:  QF1,QA1\n",
      "CONDITION:  ASK IF QA1 = 2 ( FRANCE ) IF QF1 = 1\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  qa1.any(2) \n",
      "\n",
      "\n",
      "Sample index 230\n",
      "QID:  Q1011\n",
      "CONDITION:  Screenout if not started in past three months: If not Q1011 A1 OR A2 OR A3 OR A4\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q1011.any(,,) \n",
      "\n",
      "\n",
      "Sample index 240\n",
      "QID:  3006,30041\n",
      "CONDITION:  SHOW IF  Q30041=1 or 2\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  30041.any(1,2) \n",
      "\n",
      "\n",
      "Sample index 250\n",
      "QID:  Q58a,Q57\n",
      "CONDITION:  ASK Q58a IF 1 SELECTED IN Q57.\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q57.any(1) \n",
      "\n",
      "\n",
      "Sample index 260\n",
      "QID:  Q12,Q8\n",
      "CONDITION:  ASK Q12 IF AT LEAST ONE ANSWER AT Q8\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q8.answered() \n",
      "\n",
      "\n",
      "Sample index 270\n",
      "QID:  Q4a,Q1,Q2,Q4\n",
      "CONDITION:  ASK Q4a IF DID NOT SELECT 7 AT Q1 AND Q2 OR 1 SELECTED AT Q4\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q1.any(7)or q2.any(1) \n",
      "\n",
      "\n",
      "Sample index 280\n",
      "QID:  Question2\n",
      "CONDITION:  Screenout if Age DOES NOT EQUAL 18-75\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  question2.notany(18) \n",
      "\n",
      "\n",
      "Sample index 290\n",
      "QID:  Q.CR\n",
      "CONDITION:  PROGRAMMER:  RESPONDENT MUST BE QCR -1 OR -2 TO CONTINUE. DO NOT TERM RESPONDENT.  ALLOW PROGRAM TO CONTINUE.\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q.any(1) \n",
      "\n",
      "\n",
      "Sample index 300\n",
      "QID:  8010\n",
      "CONDITION:  SCREEN OUT (under 18 and above 65)\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  8010<18 or 8010>65 \n",
      "\n",
      "\n",
      "Sample index 310\n",
      "QID:  Q4,Q2\n",
      "CONDITION:  ASK Q4 IF 7 NOT SELECTED AT Q2\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q2.notany(7) \n",
      "\n",
      "\n",
      "Sample index 320\n",
      "QID:  Q54,Q53\n",
      "CONDITION:  ASK IF Q53=2\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q53.any(2) \n",
      "\n",
      "\n",
      "Sample index 330\n",
      "QID:  S2\n",
      "CONDITION:  Exclude IF AGE<18 OR >55\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  s2 <18 or s2 >55 \n",
      "\n",
      "\n",
      "Sample index 340\n",
      "QID:  1023,1300,1301\n",
      "CONDITION:  SOCCER LOVER IF SELECTED 4 or 5 at 1300 OR 1 or 2 at 1301\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  1300.any(4,5,1,2) \n",
      "\n",
      "\n",
      "Sample index 350\n",
      "QID:  4056,4055\n",
      "CONDITION:  Ask  4056 if 1 at 4055\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  4055.any(1) \n",
      "\n",
      "\n",
      "Sample index 360\n",
      "QID:  Q17A,QD\n",
      "CONDITION:  ASK ONLY IF QD = 1 \n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  qd.any(1) \n",
      "\n",
      "\n",
      "Sample index 370\n",
      "QID:  QG2,QG1\n",
      "CONDITION:  ASK QG2 IF QG1 = 1\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  qg1.any(1) \n",
      "\n",
      "\n",
      "Sample index 380\n",
      "QID:  Q1710\n",
      "CONDITION:  ROUTING IF: respondent is aware of advertising of Heineken (Q1700=A1)\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  .any() \n",
      "\n",
      "\n",
      "Sample index 390\n",
      "QID:  Q1711,Q1700\n",
      "CONDITION:  ROUTING IF: respondent can (partially) remember what Samsung wanted to make clear(Q1710=A1/A2)\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  .any() \n",
      "\n",
      "\n",
      "Sample index 400\n",
      "QID:  2205,22017\n",
      "CONDITION:  Ask if coded 1 in 22017\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  22017.any(1) \n",
      "\n",
      "\n",
      "Sample index 410\n",
      "QID:  8010\n",
      "CONDITION:  [Screen out if younger than 18 OR 64 or older]\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  8010<18 or 8010>64 \n",
      "\n",
      "\n",
      "Sample index 420\n",
      "QID:  Q1014,Q1002,Q1003\n",
      "CONDITION:  ROUTING: Q1002–A1 OR Q1003–A2\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q1002.any()or .any() \n",
      "\n",
      "\n",
      "Sample index 430\n",
      "QID:  S7\n",
      "CONDITION:  Terminate at end of screener if <75%\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  s7<75 \n",
      "\n",
      "\n",
      "Sample index 440\n",
      "QID:  Q80:Q82,Q79\n",
      "CONDITION:  ASK Q80 TO Q82 IF 2 OR 3 AT Q79\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q82.any(2,3) \n",
      "\n",
      "\n",
      "Sample index 450\n",
      "QID:  8012\n",
      "CONDITION:  Younger than 18 years Screen out\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  8012<18 \n",
      "\n",
      "\n",
      "Sample index 460\n",
      "QID:  QC,QA1\n",
      "CONDITION:  ASK IF QA1 = 1 OR 2 (US/CANADA)\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  qa1.any(1,2) \n",
      "\n",
      "\n",
      "Sample index 470\n",
      "QID:  QA2,QA1\n",
      "CONDITION:  ASK IF QA1 = 2 . PROGRAMMER : CONTINUE REMAINDER OF QUESTIONNAIRE IN THE SELECTED LANGUAGE .\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  qa1.any(2) \n",
      "\n",
      "\n",
      "Sample index 480\n",
      "QID:  1009,Q1008\n",
      "CONDITION:  Ask only to those who selected 1 in Q1008\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q1008.any(1) \n",
      "\n",
      "\n",
      "Sample index 490\n",
      "QID:  QD,QA1\n",
      "CONDITION:  ASK IF QA1 = 1\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  qa1.any(1) \n",
      "\n",
      "\n",
      "Sample index 500\n",
      "QID:  3302,Q3260\n",
      "CONDITION:  IF Q3260, A2\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q3260.any() \n",
      "\n",
      "\n",
      "Sample index 510\n",
      "QID:  Q100103,Q1002,Q1003\n",
      "CONDITION:  ROUTING: Q1002–A1 OR Q1003–A2\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q1002.any()or .any() \n",
      "\n",
      "\n",
      "Sample index 520\n",
      "QID:  1008\n",
      "CONDITION:  IF RESPONDENT DOES NOT USE THESE SERVICES CODE 7 IN 1008  Thank & End\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  1008.notany(7) \n",
      "\n",
      "\n",
      "Sample index 530\n",
      "QID:  4052a,40522\n",
      "CONDITION:  Ask 4052a if 40522 = 4 or 5\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  40522.any(4,5) \n",
      "\n",
      "\n",
      "Sample index 540\n",
      "QID:  1012,Q1002\n",
      "CONDITION:  IF BOUGHT IPL (Q1002, A2)\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q1002.any() \n",
      "\n",
      "\n",
      "Sample index 550\n",
      "QID:  S5\n",
      "CONDITION:  IF <2 OR >35 TERMINATE\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  s5 <2 or s5 >35 \n",
      "\n",
      "\n",
      "Sample index 560\n",
      "QID:  Q5552,Q1002,Q1004\n",
      "CONDITION:  ROUTING: Q1002–A2 OR Q1003–A1\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q1002.any()or .any() \n",
      "\n",
      "\n",
      "Sample index 570\n",
      "QID:  Q585801,Q1002,Q1008\n",
      "CONDITION:  ROUTING: Q1002–A2 OR Q1003–A1\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q1002.any()or .any() \n",
      "\n",
      "\n",
      "Sample index 580\n",
      "QID:  Q5\n",
      "CONDITION:  ROUTING IF: respondent has used at least 1 product\n",
      "OUTPUT:  nan \n",
      "\n",
      "Predicted OUTPUT:  q5.notbetween(1:) \n",
      "\n",
      "\n",
      "\n",
      "Saved predictions to [./data/MT_test_submission_with_predcitions.xlsx]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" predict.py\n",
    "This file reads and preproces the test dataset. Loades a trained seq2seq model\n",
    "and predict the iput for each sample in test dataset. It writes prediction results\n",
    "to a file and print to shell\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "### Import required packages\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from tensorflow.python import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "MT_TEST_CORPUS_PATH                 = \"./data/MT_test_submission.xlsx\"\n",
    "MT_TEST_CORPUS_PATH_WITH_PREDCITION = \"./data/MT_test_submission_with_predcitions.xlsx\"\n",
    "\n",
    "## Import helper functions and constants\n",
    "from tools import read_data, prepare_data, replace_using_dict, pad_with_zero, write_data, log_to_shell\n",
    "from train import MT_SEQ2SEQ_MODEL_PATH, MT_META_DATA_FILE_PATH\n",
    "from train import create_seq2seq_inference_model\n",
    "from train import encoder_seq_length, decoder_seq_length, encoder_vocab_size, decoder_vocab_size, num_latent_dim\n",
    "\n",
    "## Specify prediction paramets\n",
    "# Beam serahc paramets to predict the most likely target sequence\n",
    "beam_search_max_branch = 3 # Maximum number of branch at each time step for beam search\n",
    "beam_search_max_depth = 4  # Maimum sequnce step to branch in beam search\n",
    "\n",
    "def decode_sequence(input_seq, encoder_model, decoder_model, word2id, id2word):\n",
    "    \"\"\" Decodes an input sequnce uing the enoder and decoder model of trained seq2seq model\n",
    "    Beam serahc algorithm is used to find a decoded sequnce with highed liklihood.\n",
    "    Args:\n",
    "        input_seq: Input sequnce\n",
    "        encoder_model: Enoder model of the seq2seq model (Keras)\n",
    "        decoder_model: Decoder model of the seq2seq model (keras)\n",
    "        word2id: Python dictionary to conver word to id\n",
    "        id2word: Python dictionary to conver id to word\n",
    "    Returns:\n",
    "        decoded_seq: Decoded sequence predicted by the model\n",
    "        decoded_seq_prob: The linkleihood of the predicted sequnce by the model\n",
    "    \"\"\"\n",
    "    # Encode the input as state vectors.\n",
    "    encoder_input = np.zeros((1, len(input_seq), encoder_vocab_size))\n",
    "    for t, word_id in enumerate(input_seq):\n",
    "        encoder_input[0, t, word_id] = 1\n",
    "\n",
    "    states_value = encoder_model.predict([encoder_input])\n",
    "    # Generate empty target sequence of length 1.\n",
    "    decoder_input = np.zeros((1, 1, decoder_vocab_size))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    decoder_input[0, 0, word2id['<BOS>'] ] = 1 \n",
    "    seq_length = 0\n",
    "    decoded_seq, decoded_seq_prob, _ = decode_sequence_beam(decoder_model, decoder_input, states_value, word2id, seq_length)\n",
    "    \n",
    "    return decoded_seq, decoded_seq_prob\n",
    "\n",
    "def decode_sequence_beam(decoder_model, decoder_input, states_value, word2id, seq_length):\n",
    "    \"\"\" This function decodes a sequnce using beam search. That is in each step of\n",
    "    decoding, search space tree is branched based on the number of specified number_search_branch\n",
    "    parameter for maximum depth of beam_search_max_depth\n",
    "    The beam search algorithm is implemented using a recursive call of this function itself.\n",
    "    Args:\n",
    "        decoder_model: Decoder model of the seq2seq model (keras)\n",
    "        decoder_input: The input to decoder in each step\n",
    "        states_value: The previous state values input\n",
    "        word2id: Python dictionary to conver word to id\n",
    "        seq_length: Current Sequence length from the begining of sequnce (used to control beam search depth)\n",
    "    Returns:\n",
    "        sampled_seq: Sampled sequence upto this step (from end to this step, reursive function call)\n",
    "        sampled_seq_prob: The linklihood of sampled sequnce upto this step (from end to this step)\n",
    "        sampled_seq_length:The sampled Sequnce length to the the end of sequnce (from end to this step)\n",
    "    \"\"\"\n",
    "    ## Get probabilitis of next word in the sequnce and state values\n",
    "    output_tokens, h, c = decoder_model.predict([decoder_input] + states_value)\n",
    "    \n",
    "    ## Update states\n",
    "    states_value = [h, c]\n",
    "    \n",
    "    ## Increment sequence length\n",
    "    seq_length += 1\n",
    "    \n",
    "    ## Choose number of branches to split tree for beam search\n",
    "    # To avoid too many searches will branch up to beam_search_max_depth sequnce length\n",
    "    if seq_length < beam_search_max_depth:\n",
    "        number_search_branch = beam_search_max_branch\n",
    "    else:\n",
    "        number_search_branch = 1\n",
    "    \n",
    "    ## Choose tokens with highest probabities\n",
    "    beam_top_token_indecies = np.argsort(output_tokens[0, -1, :])[-number_search_branch:]\n",
    "    \n",
    "    sampled_seq_list = []        # List of sampled sequnce from end to this step\n",
    "    sampled_seq_prob_list = []   # List of liklihood for th sampled sequnce from end to this step\n",
    "    sampled_seq_length_list = [] # List of lenght for sampled sequnce from end to this step\n",
    "    ## Split the search space for sequnce to differenr barnches\n",
    "    for beam in range(number_search_branch):\n",
    "        sampled_token_index = beam_top_token_indecies[beam]\n",
    "        sampled_token_prob  = output_tokens[0, -1, sampled_token_index]\n",
    "        if sampled_token_index == word2id['<EOS>'] or seq_length == decoder_seq_length:\n",
    "            return [sampled_token_index], sampled_token_prob, 0.00000001 # smalle number to avoid divde by zero\n",
    "        else:\n",
    "            ## Update the target sequence (of length 1).\n",
    "            decoder_input = np.zeros((1, 1, decoder_vocab_size))\n",
    "            decoder_input[0, 0, sampled_token_index] = 1\n",
    "            \n",
    "            ## recusrive call to decode_sequence_beam function itself to find\n",
    "            ## best sequnce from this point to the end\n",
    "            sampled_seq, sampled_seq_prob, sampled_seq_length = decode_sequence_beam(decoder_model, decoder_input, states_value, word2id, seq_length)\n",
    "            \n",
    "            ## Save the sampled sequnce (This a sampled sequnce from end to this point)\n",
    "            sampled_seq.append(sampled_token_index)\n",
    "\n",
    "            ## calculate the Sequnce probabity from end to this step\n",
    "            sampled_seq_prob *= sampled_token_prob\n",
    "            \n",
    "            ## Append the sampled sequnce to a list\n",
    "            sampled_seq_list.append(sampled_seq)\n",
    "            ## Append the sampled sequnce probability to a list\n",
    "            sampled_seq_prob_list.append(sampled_seq_prob)\n",
    "            ## Append the sampled sequnce length to a list\n",
    "            sampled_seq_length_list.append(sampled_seq_length)\n",
    "    \n",
    "    ## Claculate weighted probabity of list sequnces (bracnh beams) from end pof sequnce to this step\n",
    "    # The sequnce probabities are ajusted for lenght, thus model will not prefer shorter length\n",
    "    # sequnces. This is required because longer sequnces are generally have lower probability \n",
    "    weighted_prob = np.log(np.array(sampled_seq_prob_list))/np.array(sampled_seq_length_list)\n",
    "    \n",
    "    ## Choose a sequnce from beam branch with the highest probability \n",
    "    best_beam = np.argmax(weighted_prob)\n",
    "    \n",
    "    return sampled_seq_list[best_beam], sampled_seq_prob_list[best_beam], sampled_seq_length_list[best_beam]+1\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\" The main steps to predict an output sequnce using the seq2seq model:\n",
    "    1. Read test dataset\n",
    "    2. Preproces each sequnce (create standarized sequnces)\n",
    "        a. Change QID and CONDITION text to lowercase\n",
    "        b. split QID and CONDITION text into tokens (words)\n",
    "        c. Replace QID tokens in each sample with standrized tokens (i.e., <QID0>, <QID1>, ...)\n",
    "        d. Replace digit tokens in each sample with standarized tokens (i.e., <DGT0>, <DGT1>, ...)\n",
    "        e. Create standardization dictionary for each sample\n",
    "        f. Add special tokens <BOS> and <EOS> to the begining and end of each sequence\n",
    "    3. Replace condition sequnce tokens with an integre id usng the encoder_word2id dictionary\n",
    "    4. Pad condition sequnce with zero to create a fixed size input sequnce\n",
    "        a. Input sequnce is pre-padded with zero\n",
    "    5. Extract Encoder and Decoder parts of saved seq2seq model\n",
    "    6. Use a beam search algorithm to predict the output sequnce\n",
    "    7. Reverse predicted output sequnce to words using the decoder_id2word dictionary \n",
    "    8. Revrese Digit and QID standardization from the predicted output\n",
    "    9. Save the precited outputs to a file\n",
    "    \"\"\"\n",
    "\n",
    "    # Test data path\n",
    "    test_data_path = MT_TEST_CORPUS_PATH\n",
    "\n",
    "    # Output data path\n",
    "    test_data_output_path = MT_TEST_CORPUS_PATH_WITH_PREDCITION\n",
    "\n",
    "    # Make sure an Encoder model exists\n",
    "    if not os.path.exists(MT_SEQ2SEQ_MODEL_PATH):\n",
    "        print(\"\\n The seq2seq model [%s] does not exist\\n\" % MT_SEQ2SEQ_MODEL_PATH)\n",
    "        return\n",
    "\n",
    "    # Load model and metadata\n",
    "    model = load_model(MT_SEQ2SEQ_MODEL_PATH)\n",
    "\n",
    "    with open(MT_META_DATA_FILE_PATH,'rb') as f:\n",
    "        [condition_word2id, condition_id2word, output_word2id, output_id2word] = pickle.load(f)\n",
    "\n",
    "    print(\"\\nLoaded a trained seq2seq model from [{}]\\n\".format(MT_SEQ2SEQ_MODEL_PATH))\n",
    "\n",
    "    encoder_model, decoder_model = create_seq2seq_inference_model(model, num_latent_dim)\n",
    "    \n",
    "    #test_data_path = MT_TRAINING_CORPUS_PATH\n",
    "    \n",
    "    #Read dataset from Excel file\n",
    "    qids_raw, conditions_raw, output_raw = read_data(test_data_path)\n",
    "    print(\"\\nLoaded test dataset from [{}]\\n\".format(test_data_path))\n",
    "\n",
    "    # Preprocess the raw input text data\n",
    "    _, conditions, _, dictionaries_lemanization = prepare_data(qids_raw, conditions_raw, output_raw)\n",
    "    \n",
    "    # Replace words of qid, condition and ouput with corresponding id in dictonaries\n",
    "    conditions = replace_using_dict(conditions, condition_word2id, drop_unknown=True)\n",
    "\n",
    "    # Fix all sequnces length to a fixed size with padding\n",
    "    conditions = pad_with_zero(conditions, encoder_seq_length,'pre')\n",
    "\n",
    "    outputs_predcited = [None for _ in conditions]\n",
    "    for sample_index, condition in enumerate(conditions):\n",
    "\n",
    "        input_seq = condition\n",
    "        decoded_seqeunce, _ = decode_sequence(input_seq, encoder_model, decoder_model, output_word2id, output_id2word)\n",
    "        \n",
    "        decoded_seqeunce = replace_using_dict([decoded_seqeunce], output_id2word)\n",
    "        decoded_seqeunce = replace_using_dict(decoded_seqeunce, dictionaries_lemanization[sample_index])\n",
    "\n",
    "        decoded_seqeunce = [seq for seq in decoded_seqeunce[0] if seq != '<PAD>' and seq != '<EOS>'\\\n",
    "                                                                and '<QID' not in seq and '<DGT' not in seq]\n",
    "        decoded_seqeunce = reversed(decoded_seqeunce)\n",
    "        decoded_seqeunce = ''.join(decoded_seqeunce)\n",
    "\n",
    "        outputs_predcited[sample_index] = decoded_seqeunce\n",
    "\n",
    "        if sample_index % 10 == 0:\n",
    "            log_to_shell(sample_index, qids_raw[sample_index],\n",
    "                           conditions_raw[sample_index], output_raw[sample_index],\n",
    "                           decoded_seqeunce )\n",
    "        \n",
    "    write_data(qids_raw, conditions_raw, outputs_predcited, test_data_output_path)\n",
    "    print(\"\\nSaved predictions to [{}]\\n\".format(test_data_output_path))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
